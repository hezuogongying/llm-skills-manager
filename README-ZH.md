# LLM Skills Manager

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![SOLID](https://img.shields.io/badge/Design-SOLID-orange.svg)](https://en.wikipedia.org/wiki/SOLID)

ä¸€ä¸ªé€šç”¨çš„ Python åº“ï¼Œç”¨äºè§£æå’Œè°ƒç”¨ç¬¦åˆ [Agent Skills è§„èŒƒ](https://agentskills.io) çš„ Skillsï¼Œæ”¯æŒå¤šç§ LLM åç«¯ã€‚

[GitHub](https://github.com/hezuogongying/llm-skills-manager) | [Gitee](https://gitee.com/hezuo_111_admin/llm-skills-manager)

</div>

---

## âœ¨ ç‰¹æ€§

- âœ… **å®Œå…¨å…¼å®¹** agentskills.io è§„èŒƒ
- âœ… **å¤šåç«¯æ”¯æŒ** - OpenAIã€Anthropic Claudeã€Google Geminiã€Ollama
- âœ… **æ™ºèƒ½åŒ¹é…** - è‡ªåŠ¨è¯­ä¹‰åŒ¹é…æœ€åˆé€‚çš„ Skill
- âœ… **å¤šè½®å¯¹è¯** - æ”¯æŒå¯¹è¯å†å²ç®¡ç†
- âœ… **SOLID æ¶æ„** - å•ä¸€èŒè´£ã€ä¾èµ–æ³¨å…¥ã€æ˜“äºæµ‹è¯•
- âœ… **è‡ªåŠ¨å‘ç°** - è‡ªåŠ¨åŠ è½½ `skills/` å’Œ `.claude/skills/` ç›®å½•
- âœ… **Web ç•Œé¢** - åŸºäº Streamlit çš„å¯è§†åŒ–åº”ç”¨
- âœ… **å•å…ƒæµ‹è¯•** - å®Œæ•´çš„æµ‹è¯•è¦†ç›–

---

## ğŸ“¦ å®‰è£…

```bash
# åŸºç¡€ä¾èµ–
pip install pyyaml

# LLM SDKï¼ˆæ ¹æ®éœ€è¦é€‰æ‹©ï¼‰
pip install openai               # OpenAI
pip install anthropic            # Anthropic Claude
pip install google-generativeai  # Google Gemini
pip install requests             # Ollama

# Web åº”ç”¨ï¼ˆå¯é€‰ï¼‰
pip install streamlit
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
# OpenAI
OPENAI_API_KEY=sk-your-api-key

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-your-api-key

# Google Gemini
GOOGLE_API_KEY=your-api-key

# Ollama (æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ API Key)
# OLLAMA_BASE_URL=http://localhost:11434
```

### 2. åŸºæœ¬ä½¿ç”¨

```python
from skill_manager import SkillManager, OllamaBackend

# åˆå§‹åŒ–ï¼ˆè‡ªåŠ¨åŠ è½½ skills/ å’Œ .claude/skills/ï¼‰
manager = SkillManager()

# é€‰æ‹©åç«¯
backend = OllamaBackend(model="llama3.2")

# æ‰§è¡Œï¼ˆè‡ªåŠ¨åŒ¹é… Skillï¼‰
response = manager.execute("å¸®æˆ‘å®¡æŸ¥è¿™æ®µä»£ç ", backend)
print(response)
```

### 3. åˆ›å»º Skill

```python
from skill_manager import create_skill_template

skill_dir = create_skill_template(
    output_dir="./skills",
    name="code-review",
    description="ä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œå‘ç°å®‰å…¨æ¼æ´å’Œæ€§èƒ½é—®é¢˜",
    instructions="""# Code Review Skill

ä½ æ˜¯ä¸€ä½èµ„æ·±ä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œä¸“æ³¨äºï¼š
- å®‰å…¨æ¼æ´ï¼ˆSQLæ³¨å…¥ã€XSSç­‰ï¼‰
- æ€§èƒ½é—®é¢˜
- ä»£ç è§„èŒƒ
"""
)
```

### 4. ä½¿ç”¨ä¸åŒåç«¯

```python
from skill_manager import (
    OpenAIBackend,
    AnthropicBackend,
    GoogleBackend,
    OllamaBackend
)

# OpenAI GPT-4
backend = OpenAIBackend(model="gpt-4o")

# Anthropic Claude
backend = AnthropicBackend(model="claude-sonnet-4-20250514")

# Google Gemini
backend = GoogleBackend(model="gemini-2.0-flash")

# Ollama æœ¬åœ°
backend = OllamaBackend(model="llama3.2")
```

---

## ğŸ¯ Ollama æœ¬åœ°æ¨¡å‹

æ— éœ€ API Keyï¼Œå®Œå…¨æœ¬åœ°è¿è¡Œï¼š

```bash
# 1. å®‰è£… Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. å¯åŠ¨æœåŠ¡
ollama serve

# 3. ä¸‹è½½æ¨¡å‹
ollama pull llama3.2

# 4. ä½¿ç”¨
python -c "
from skill_manager import SkillManager, OllamaBackend
manager = SkillManager()
backend = OllamaBackend(model='llama3.2')
print(manager.execute('ä½ å¥½', backend))
"
```

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

æœ¬é¡¹ç›®ä¸¥æ ¼éµå¾ª **SOLID åŸåˆ™**ï¼š

```
skill_manager/
â”œâ”€â”€ core/                    # é¢†åŸŸå±‚
â”‚   â”œâ”€â”€ entities/            # å®ä½“ï¼ˆSkill, Messageï¼‰
â”‚   â”œâ”€â”€ interfaces/          # æ¥å£å®šä¹‰ï¼ˆä¾èµ–å€’ç½®ï¼‰
â”‚   â””â”€â”€ services/            # é¢†åŸŸæœåŠ¡ï¼ˆå•ä¸€èŒè´£ï¼‰
â”‚       â”œâ”€â”€ skill_loader.py  # åŠ è½½ Skill
â”‚       â”œâ”€â”€ skill_matcher.py # è¯­ä¹‰åŒ¹é… Skill
â”‚       â”œâ”€â”€ prompt_builder.py# æ„å»ºç³»ç»Ÿæç¤º
â”‚       â””â”€â”€ skill_executor.py# æ‰§è¡Œè¯·æ±‚
â”œâ”€â”€ infrastructure/          # åŸºç¡€è®¾æ–½å±‚
â”‚   â””â”€â”€ backends/            # LLM åç«¯å®ç°
â”œâ”€â”€ facades/                 # å¤–è§‚æ¨¡å¼
â”‚   â””â”€â”€ skill_manager.py     # SkillManager
â”œâ”€â”€ utils.py                 # ä¾¿æ·å‡½æ•°
â””â”€â”€ webapp.py                # Streamlit Web åº”ç”¨
```

### SOLID åŸåˆ™

| åŸåˆ™ | è¯´æ˜ | å®ç° |
|:---:|------|------|
| **S** å•ä¸€èŒè´£ | æ¯ä¸ªç±»åªè´Ÿè´£ä¸€ä»¶äº‹ | `SkillLoader` åªåŠ è½½ï¼Œ`SkillMatcher` åªåŒ¹é… |
| **O** å¼€é—­åŸåˆ™ | å¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å…³é—­ | é€šè¿‡ `ILLMBackend` æ¥å£æ·»åŠ æ–°åç«¯ |
| **L** é‡Œæ°æ›¿æ¢ | å®ç°å¯æ›¿æ¢åŸºç±» | æ‰€æœ‰ `Backend` å¯äº’æ¢ |
| **I** æ¥å£éš”ç¦» | æ¥å£ç®€æ´æ˜ç¡® | `ILLMBackend` åªå®šä¹‰å¿…è¦æ–¹æ³• |
| **D** ä¾èµ–å€’ç½® | ä¾èµ–æŠ½è±¡è€Œéå…·ä½“ | ä½¿ç”¨ä¾èµ–æ³¨å…¥ |

### ä¾èµ–æ³¨å…¥

```python
from skill_manager import SkillManager, ISkillMatcher, SemanticSkillMatcher

# è‡ªå®šä¹‰åŒ¹é…å™¨
class MyMatcher(ISkillMatcher):
    def match(self, user_input, skills, backend):
        # è‡ªå®šä¹‰åŒ¹é…é€»è¾‘
        return skills[0] if skills else None

# æ³¨å…¥è‡ªå®šä¹‰ç»„ä»¶
manager = SkillManager(matcher=MyMatcher())
```

---

## ğŸ’» Web åº”ç”¨

### åŠŸèƒ½ç‰¹æ€§

- ğŸ’¬ **æ™ºèƒ½å¯¹è¯** - å¤šè½®å¯¹è¯ï¼Œè‡ªåŠ¨åŒ¹é… Skill
- ğŸ“š **Skill ç®¡ç†** - åˆ›å»ºã€åŠ è½½ã€éªŒè¯ã€åˆ é™¤
- âš™ï¸ **åç«¯é…ç½®** - å¯è§†åŒ–é…ç½® LLM åç«¯

### å¯åŠ¨

```bash
streamlit run webapp.py
```

è®¿é—® http://localhost:8501

---

## ğŸ“– API å‚è€ƒ

### SkillManager

```python
from skill_manager import SkillManager

manager = SkillManager()

# åŠ è½½ Skills
manager.load_default_skills()              # è‡ªåŠ¨åŠ è½½é»˜è®¤ç›®å½•
manager.load_skill("./skills/my-skill")    # åŠ è½½å•ä¸ª
manager.load_skills_from_directory("./skills")  # æ‰¹é‡åŠ è½½

# è·å– Skill
skill = manager.get_skill("my-skill")

# åˆ—å‡ºæ‰€æœ‰ Skills
for meta in manager.list_skills():
    print(f"{meta.name}: {meta.description}")

# æ‰§è¡Œ
response = manager.execute(
    user_input="Your question",
    backend=backend,
    auto_match=True,           # è‡ªåŠ¨åŒ¹é…
    skill_name=None,           # æˆ–æŒ‡å®š Skill
    include_references=False,  # åŒ…å«å‚è€ƒæ–‡æ¡£
    conversation_history=[]    # å¯¹è¯å†å²
)
```

### éªŒè¯ Skill

```python
from skill_manager import validate_skill

is_valid, errors = validate_skill("./skills/my-skill")
if not is_valid:
    for error in errors:
        print(f"âŒ {error}")
```

### è‡ªå®šä¹‰åç«¯

```python
from skill_manager import ILLMBackend, IModelConfig

class MyBackend(ILLMBackend):
    def complete(self, messages, system_prompt=None, tools=None):
        # å®ç° LLM è°ƒç”¨
        return "Response"

    def get_model_name(self):
        return "my-model"

    def configure(self, config: IModelConfig):
        # é…ç½®é€»è¾‘
        pass
```

---

## ğŸ“‹ Skill è§„èŒƒ

### ç›®å½•ç»“æ„

```
my-skill/
â”œâ”€â”€ SKILL.md          # å¿…éœ€ï¼šä¸»æ–‡ä»¶
â”œâ”€â”€ scripts/          # å¯é€‰ï¼šå¯æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ helper.py
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ references/       # å¯é€‰ï¼šå‚è€ƒæ–‡æ¡£
â”‚   â””â”€â”€ api.md
â””â”€â”€ assets/          # å¯é€‰ï¼šèµ„æºæ–‡ä»¶
    â””â”€â”€ template.json
```

### SKILL.md æ ¼å¼

```markdown
---
name: my-skill          # å¿…éœ€ï¼šå°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦
description: What this does   # å¿…éœ€ï¼šç®€è¦æè¿°
version: "1.0.0"        # å¯é€‰ï¼šç‰ˆæœ¬å·
author: your-name        # å¯é€‰ï¼šä½œè€…
---

# Skill Instructions

è¿™é‡Œæ˜¯ LLM ä¼šæ”¶åˆ°çš„æŒ‡ä»¤...
```

---

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m unittest discover tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -m unittest tests.test_skill_manager

# æŸ¥çœ‹è¦†ç›–ç‡
python -m coverage run -m unittest discover tests/
python -m coverage report
```

---

## ğŸ”— å…¼å®¹æ€§

æ­¤åº“åˆ›å»ºçš„ Skills ä¸ä»¥ä¸‹å¹³å°å…¼å®¹ï¼š

| å¹³å° | æ”¯æŒæƒ…å†µ |
|------|:--------:|
| Claude Code | âœ… |
| OpenAI Codex | âœ… |
| GitHub Copilot | âœ… |
| Cursor | âœ… |
| VS Code | âœ… |

---

## ğŸ“„ License

[MIT License](LICENSE)

---

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=hezuogongying/llm-skills-manager&type=Date)](https://star-history.com/#hezuogongying/llm-skills-manager&Date)

---

<div align="center">

**å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Star â­**

Made with â¤ï¸ by [LLM Skills Manager](https://github.com/hezuogongying/llm-skills-manager)

</div>
