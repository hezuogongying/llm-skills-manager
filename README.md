# Agent Skills Manager

ä¸€ä¸ªé€šç”¨çš„ Python åº“ï¼Œç”¨äºè§£æå’Œè°ƒç”¨ç¬¦åˆ [Agent Skills è§„èŒƒ](https://agentskills.io) çš„ Skillsï¼Œæ”¯æŒå¤šç§ LLM åç«¯ã€‚

## ç‰¹æ€§

- âœ… å®Œå…¨å…¼å®¹ agentskills.io è§„èŒƒ
- âœ… æ”¯æŒå¤šç§ LLM åç«¯ï¼šOpenAIã€Anthropic Claudeã€Google Geminiã€Ollama
- âœ… è‡ªåŠ¨ Skill åŒ¹é…ï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰
- âœ… æ”¯æŒå¤šè½®å¯¹è¯
- âœ… Skill éªŒè¯å·¥å…·
- âœ… æ˜“äºæµ‹è¯•å’Œæ‰©å±•
- âœ… **SOLID æ¶æ„è®¾è®¡**

## å®‰è£…

```bash
# åŸºç¡€å®‰è£…
pip install pyyaml

# æ ¹æ®éœ€è¦å®‰è£… LLM SDK
pip install openai          # OpenAI
pip install anthropic       # Anthropic Claude
pip install google-generativeai  # Google Gemini
pip install requests        # Ollama (ä½¿ç”¨ HTTP API)
```

## ç¯å¢ƒé…ç½®

å¤åˆ¶ `.env.example` ä¸º `.env` å¹¶é…ç½®æ‚¨çš„ API å¯†é’¥ï¼š

```bash
cp .env.example .env
```

ç„¶åç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨éœ€è¦ä½¿ç”¨çš„ LLM æœåŠ¡é…ç½®ï¼š

```bash
# OpenAI
OPENAI_API_KEY=sk-your-api-key

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-your-api-key

# Google Gemini
GOOGLE_API_KEY=your-api-key

# Ollama (æœ¬åœ°ï¼Œæ— éœ€ API å¯†é’¥)
# OLLAMA_BASE_URL=http://localhost:11434  # å¯é€‰
```

## æ¶æ„è®¾è®¡

æœ¬é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ä¾¿äºæµ‹è¯•å’Œæ‰©å±•ï¼š

```
skill_manager/
â”œâ”€â”€ core/                    # é¢†åŸŸå±‚ï¼ˆæ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼‰
â”‚   â”œâ”€â”€ entities/            # å®ä½“ï¼ˆæ•°æ®ç»“æ„ï¼‰
â”‚   â”‚   â”œâ”€â”€ skill.py         # Skill å®ä½“
â”‚   â”‚   â””â”€â”€ message.py       # Message å®ä½“
â”‚   â”œâ”€â”€ interfaces/          # æ¥å£å®šä¹‰ï¼ˆä¾èµ–å€’ç½®ï¼‰
â”‚   â”‚   â””â”€â”€ llm_backend.py   # ILLMBackend æ¥å£
â”‚   â””â”€â”€ services/            # é¢†åŸŸæœåŠ¡ï¼ˆå•ä¸€èŒè´£ï¼‰
â”‚       â”œâ”€â”€ skill_loader.py      # åŠ è½½ Skill
â”‚       â”œâ”€â”€ skill_matcher.py     # åŒ¹é… Skill
â”‚       â”œâ”€â”€ prompt_builder.py    # æ„å»ºæç¤º
â”‚       â””â”€â”€ skill_executor.py    # æ‰§è¡Œè¯·æ±‚
â”œâ”€â”€ infrastructure/          # åŸºç¡€è®¾æ–½å±‚ï¼ˆå¤–éƒ¨é›†æˆï¼‰
â”‚   â””â”€â”€ backends/            # LLM åç«¯å®ç°
â”‚       â”œâ”€â”€ openai_backend.py
â”‚       â”œâ”€â”€ anthropic_backend.py
â”‚       â”œâ”€â”€ google_backend.py
â”‚       â””â”€â”€ ollama_backend.py
â”œâ”€â”€ facades/                 # å¤–è§‚æ¨¡å¼ï¼ˆç®€åŒ– APIï¼‰
â”‚   â””â”€â”€ skill_manager.py     # SkillManager å¤–è§‚ç±»
â””â”€â”€ utils.py                 # ä¾¿æ·å‡½æ•°
```

### SOLID åŸåˆ™åº”ç”¨

| åŸåˆ™ | è¯´æ˜ | å®ç° |
|------|------|------|
| **S** å•ä¸€èŒè´£ | æ¯ä¸ªç±»åªè´Ÿè´£ä¸€ä»¶äº‹ | `SkillLoader` åªè´Ÿè´£åŠ è½½ï¼Œ`SkillMatcher` åªè´Ÿè´£åŒ¹é… |
| **O** å¼€é—­åŸåˆ™ | å¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å…³é—­ | é€šè¿‡ `ILLMBackend` æ¥å£æ·»åŠ æ–°åç«¯ |
| **L** é‡Œæ°æ›¿æ¢ | å®ç°å¯ä»¥æ›¿æ¢åŸºç±» | æ‰€æœ‰ `Backend` å®ç°å¯äº’æ¢ |
| **I** æ¥å£éš”ç¦» | æ¥å£ç®€æ´æ˜ç¡® | `ILLMBackend` åªå®šä¹‰å¿…è¦æ–¹æ³• |
| **D** ä¾èµ–å€’ç½® | ä¾èµ–æŠ½è±¡è€Œéå…·ä½“ | ä½¿ç”¨ä¾èµ–æ³¨å…¥ï¼Œé«˜å±‚æ¨¡å—ä¾èµ–æ¥å£ |

### ä¾èµ–æ³¨å…¥ç¤ºä¾‹

```python
from skill_manager import (
    SkillManager,
    ISkillMatcher,
    IPromptBuilder,
    SemanticSkillMatcher,
    SystemPromptBuilder
)

# è‡ªå®šä¹‰åŒ¹é…å™¨
class MyMatcher(ISkillMatcher):
    def match(self, user_input, skills, backend):
        # è‡ªå®šä¹‰åŒ¹é…é€»è¾‘
        pass

# ä½¿ç”¨ä¾èµ–æ³¨å…¥
manager = SkillManager(
    matcher=MyMatcher(),
    prompt_builder=SystemPromptBuilder()
)
```

## å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»º Skill

```python
from skill_manager import create_skill_template

skill_dir = create_skill_template(
    output_dir="./skills",
    name="code-review",
    description="Reviews code for bugs and security issues.",
    instructions="""# Code Review Skill

You are an expert code reviewer. Analyze code for:
- Security vulnerabilities
- Performance issues
- Best practices
"""
)
```

æˆ–æ‰‹åŠ¨åˆ›å»º `skills/code-review/SKILL.md`:

```markdown
---
name: code-review
description: Reviews code for bugs and security issues.
---

# Code Review Skill

You are an expert code reviewer...
```

### 2. åŠ è½½å¹¶ä½¿ç”¨ Skill

```python
from skill_manager import SkillManager, OpenAIBackend

# åˆå§‹åŒ–
manager = SkillManager()
manager.load_skills_from_directory("./skills")

# é€‰æ‹©åç«¯
backend = OpenAIBackend(api_key="your-api-key")

# æ‰§è¡Œï¼ˆè‡ªåŠ¨åŒ¹é… Skillï¼‰
response = manager.execute(
    "Review this code: def foo(): pass",
    backend
)
print(response)
```

### 3. ä½¿ç”¨ä¸åŒåç«¯

```python
from skill_manager import (
    OpenAIBackend,
    AnthropicBackend,
    GoogleBackend,
    OllamaBackend
)

# OpenAI
backend = OpenAIBackend(model="gpt-4o")

# Anthropic Claude
backend = AnthropicBackend(model="claude-sonnet-4-20250514")

# Google Gemini
backend = GoogleBackend(model="gemini-2.0-flash")

# Ollama (æœ¬åœ°)
backend = OllamaBackend(model="llama3.2", base_url="http://localhost:11434")
```

#### Ollama æœ¬åœ°æ¨¡å‹ä½¿ç”¨

Ollama è®©æ‚¨å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œå¼€æºå¤§æ¨¡å‹ï¼Œæ— éœ€ API å¯†é’¥ã€‚

1. **å®‰è£… Ollama**ï¼š
   - è®¿é—® [ollama.ai](https://ollama.ai/) ä¸‹è½½å®‰è£…
   - æˆ–ä½¿ç”¨å‘½ä»¤è¡Œï¼š`curl -fsSL https://ollama.ai/install.sh | sh`

2. **å¯åŠ¨æœåŠ¡**ï¼š
   ```bash
   ollama serve
   ```

3. **ä¸‹è½½æ¨¡å‹**ï¼š
   ```bash
   # Llama 3.2 (æ¨è)
   ollama pull llama3.2

   # å…¶ä»–å¯ç”¨æ¨¡å‹
   ollama pull qwen2.5       # é€šä¹‰åƒé—®
   ollama pull mistral       # Mistral
   ollama pull codellama     # Code Llama
   ```

4. **ä½¿ç”¨ç¤ºä¾‹**ï¼š
   ```python
   from skill_manager import SkillManager, OllamaBackend

   backend = OllamaBackend(model="llama3.2")
   manager = SkillManager()
   manager.load_skills_from_directory("./skills")

   response = manager.execute("Your question", backend)
   ```

## API å‚è€ƒ

### SkillManager

ä¸»è¦çš„ Skill ç®¡ç†ç±»ã€‚

```python
manager = SkillManager()

# åŠ è½½ Skills
manager.load_skill("./skills/my-skill")
manager.load_skills_from_directory("./skills")

# è·å– Skill
skill = manager.get_skill("my-skill")

# åˆ—å‡ºæ‰€æœ‰ Skills
for meta in manager.list_skills():
    print(f"{meta.name}: {meta.description}")

# æ‰§è¡Œ
response = manager.execute(
    user_input="Your question",
    backend=backend,
    auto_match=True,           # è‡ªåŠ¨åŒ¹é… Skill
    skill_name=None,           # æˆ–æŒ‡å®š Skill åç§°
    include_references=False,  # åŒ…å«å‚è€ƒæ–‡æ¡£
    conversation_history=[]    # å¯¹è¯å†å²
)
```

### SkillParser

è§£æ SKILL.md æ–‡ä»¶ã€‚

```python
from skill_manager import SkillParser

# è§£ææ–‡ä»¶
metadata, instructions = SkillParser.parse_file(Path("./SKILL.md"))

# è§£æå†…å®¹å­—ç¬¦ä¸²
metadata, instructions = SkillParser.parse_content(content)

# åŠ è½½å®Œæ•´ Skillï¼ˆåŒ…å«è„šæœ¬ã€å‚è€ƒæ–‡æ¡£ç­‰ï¼‰
skill = SkillParser.load_skill(Path("./skills/my-skill"))
```

### Skill æ•°æ®ç»“æ„

```python
@dataclass
class Skill:
    metadata: SkillMetadata  # å…ƒæ•°æ®
    instructions: str        # æŒ‡ä»¤å†…å®¹
    path: Path              # ç›®å½•è·¯å¾„
    scripts: Dict[str, str] # è„šæœ¬æ–‡ä»¶
    references: Dict[str, str]  # å‚è€ƒæ–‡æ¡£
    assets: List[Path]      # èµ„æºæ–‡ä»¶

@dataclass
class SkillMetadata:
    name: str
    description: str
    license: Optional[str]
    version: Optional[str]
    author: Optional[str]
    allowed_tools: Optional[List[str]]
    compatibility: Optional[str]
    metadata: Dict[str, Any]
```

### éªŒè¯ Skill

```python
from skill_manager import validate_skill

is_valid, errors = validate_skill("./skills/my-skill")
if not is_valid:
    for error in errors:
        print(f"Error: {error}")
```

### è‡ªå®šä¹‰åç«¯

```python
from skill_manager import LLMBackend

class MyCustomBackend(LLMBackend):
    def complete(
        self, 
        messages, 
        system_prompt=None,
        tools=None
    ) -> str:
        # å®ç°ä½ çš„ LLM è°ƒç”¨é€»è¾‘
        pass
    
    def get_model_name(self) -> str:
        return "my-custom-model"
```

## Skill è§„èŒƒ

### ç›®å½•ç»“æ„

```
my-skill/
â”œâ”€â”€ SKILL.md          # å¿…éœ€ï¼šä¸»æ–‡ä»¶
â”œâ”€â”€ scripts/          # å¯é€‰ï¼šå¯æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ helper.py
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ references/       # å¯é€‰ï¼šå‚è€ƒæ–‡æ¡£
â”‚   â”œâ”€â”€ api.md
â”‚   â””â”€â”€ examples.md
â””â”€â”€ assets/          # å¯é€‰ï¼šèµ„æºæ–‡ä»¶
    â””â”€â”€ template.json
```

### SKILL.md æ ¼å¼

```markdown
---
name: my-skill-name          # å¿…éœ€ï¼šå°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ï¼Œæœ€å¤š64å­—ç¬¦
description: What this does   # å¿…éœ€ï¼šæœ€å¤š1024å­—ç¬¦
license: MIT                  # å¯é€‰
metadata:                     # å¯é€‰
  author: your-name
  version: "1.0.0"
---

# Skill Instructions

è¿™é‡Œæ˜¯ LLM ä¼šæ”¶åˆ°çš„æŒ‡ä»¤å†…å®¹...
```

### åç§°è§„åˆ™

- æœ€å¤š 64 ä¸ªå­—ç¬¦
- åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦
- ä¸èƒ½ä»¥è¿å­—ç¬¦å¼€å¤´æˆ–ç»“å°¾

## å…¼å®¹æ€§

æ­¤åº“åˆ›å»ºçš„ Skills ä¸ä»¥ä¸‹å¹³å°å…¼å®¹ï¼š

| å¹³å° | æ”¯æŒæƒ…å†µ |
|------|----------|
| Claude Code | âœ… |
| OpenAI Codex | âœ… |
| GitHub Copilot | âœ… |
| VS Code | âœ… |
| Cursor | âœ… |
| Gemini CLI | âœ… |

## ç¤ºä¾‹

æŸ¥çœ‹ `examples.py` è·å–æ›´å¤šä½¿ç”¨ç¤ºä¾‹ï¼š

```bash
python examples.py
```

## License

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶
## ğŸ“ è”ç³»æ–¹å¼

- GitHub Issues: https://github.com/hezuogongying/pay-stack/issues
- Email: 139563281@qq.com

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©,è¯·ç»™æˆ‘ä»¬ä¸€ä¸ªStar!**

[GitHub](https://github.com/hezuogongying/pay-stack) | [Gitee](https://gitee.com/hezuo_111_admin/pay-stack)

Made with â¤ï¸ by Pay-Stack Team

</div>

---

## ğŸ’¬ èµèµæ”¯æŒ

<div align="center">

å¾®ä¿¡èµèµç  &nbsp;&nbsp;&nbsp;&nbsp; æ”¯ä»˜å®èµåŠ©ç 

<br>

<img width="200" height="200" src="assets/wx_pay.png" style="object-fit: contain;"/>
&nbsp;&nbsp;&nbsp;&nbsp;
<img width="200" height="200" src="assets/hzwy_pay.png" style="object-fit: contain;"/>

</div>

---

## ğŸ“¢ é—®é¢˜æ²Ÿé€š

<div align="center">

åŠ å¾®ä¿¡ç¾¤æ²Ÿé€š,å…³æ³¨å…¬ä¼—å·è·å–æœ€æ–°ç‰ˆæœ¬

<br>

å¾®ä¿¡ç¾¤ &nbsp;&nbsp;&nbsp;&nbsp; å…¬ä¼—å·

<br>

<img width="200" height="200" src="assets/wx_qun.png" style="object-fit: contain;"/>
&nbsp;&nbsp;&nbsp;&nbsp;
<img width="200" height="200" src="assets/gzh_vip.png" style="object-fit: contain;"/>

</div>